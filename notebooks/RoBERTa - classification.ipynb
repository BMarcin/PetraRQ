{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068b6ea2-432c-4330-829d-94d589f44b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: bmarcin. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036060f4-b3fe-4499-bd40-31f65f2bce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ds = \"../data/dev/\"\n",
    "test_ds = \"../data/test/\"\n",
    "train_ds = \"../data/train/\"\n",
    "\n",
    "notebook_path_prefix = \"../models/roberta_lm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e9cc7a-c6ec-4eb7-b3b8-5819f4a41a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\n",
    "    '<url>',\n",
    "    '<email>',\n",
    "    '<number>',\n",
    "    '<date>', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3491d32d-c91b-44b6-92b9-fe35aa50a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aabfe31d-51c0-45a8-aae7-77417170a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(notebook_path_prefix, max_len=512, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a124fcac-eefa-40e4-bf90-47016ff72be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\n",
    "    'additional_special_tokens': special_tokens\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e4ba3d4-0b5c-4f60-8f51-fd96e8d49873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>',\n",
       " 'additional_special_tokens': ['<url>', '<email>', '<number>', '<date>']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ca30b5-3ef5-4fd6-858b-1eb5c69eaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d69e86a-17fc-4bf4-91d2-1f6dd4990142",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../data/dev/in.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "data2 = pd.read_csv(\"../data/test/in.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")\n",
    "data3 = pd.read_csv(\"../data/train/in.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2556452-ad64-4260-a30d-ff67e14fac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = pd.read_csv(\"../data/dev/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "labels2 = pd.read_csv(\"../data/test/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")\n",
    "labels3 = pd.read_csv(\"../data/train/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93a7b96-9db4-473b-af65-1fb4c5ea86db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5003 5003\n"
     ]
    }
   ],
   "source": [
    "print(len(data1), len(labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d74e78a-f127-4612-8aaa-ffb0c3841dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5003 5003\n",
      "10011 10011\n",
      "85083 85083\n"
     ]
    }
   ],
   "source": [
    "print(len(data1), len(labels1))\n",
    "print(len(data2), len(labels2))\n",
    "print(len(data3), len(labels3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93dc22ad-33ea-4cf1-8152-ead84498c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7e9c199-c48b-4bc1-8244-2b2d8f7b2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = [\n",
    "    'economy',\n",
    "    'law',\n",
    "    'foreign policy',\n",
    "    'agriculture',\n",
    "    'environment',\n",
    "    'social policy',\n",
    "    'state',\n",
    "    'public authorities',\n",
    "    'taxes',\n",
    "    'transport',\n",
    "    'science',\n",
    "    'research and technology',\n",
    "    'european union',\n",
    "    'work and employment',\n",
    "    'health',\n",
    "    'education',\n",
    "    'industry',\n",
    "    'sports'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90311cc5-9080-4c99-9822-1c79fc86ec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agriculture'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set([label.strip().lower() for label in labels1.iloc[1][0].split(',')]); labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eae67904-fbc0-4822-a405-18cd486aeedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_texts, input_labels, unique_labels, tokenizer):\n",
    "        self.input_texts = input_texts\n",
    "        self.input_labels = input_labels\n",
    "        self.unique_labels = unique_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2idx = {}\n",
    "        \n",
    "        for label in self.unique_labels:\n",
    "            self.label2idx[label] = len(self.label2idx)\n",
    "            \n",
    "        print(self.label2idx)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        tokenized = tokenizer(str(self.input_texts.iloc[idx][1]))\n",
    "        labels = set([self.label2idx[label.strip().lower()] for label in self.input_labels.iloc[idx][0].split(',')])\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': torch.tensor(tokenized['input_ids']),\n",
    "            'attention_mask': torch.tensor(tokenized['attention_mask']),\n",
    "            'labels': torch.zeros([len(self.label2idx)]).index_fill_(0, torch.tensor(list(labels)), 1)\n",
    "        }\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67aef71e-9d37-4dcc-a3f4-9d6aac3e640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'economy': 0, 'law': 1, 'foreign policy': 2, 'agriculture': 3, 'environment': 4, 'social policy': 5, 'state': 6, 'public authorities': 7, 'taxes': 8, 'transport': 9, 'science': 10, 'research and technology': 11, 'european union': 12, 'work and employment': 13, 'health': 14, 'education': 15, 'industry': 16, 'sports': 17}\n"
     ]
    }
   ],
   "source": [
    "dev_ds = ClassificationDS(data1, labels1, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6da6b7c-2089-4f54-802f-de410908d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'economy': 0, 'law': 1, 'foreign policy': 2, 'agriculture': 3, 'environment': 4, 'social policy': 5, 'state': 6, 'public authorities': 7, 'taxes': 8, 'transport': 9, 'science': 10, 'research and technology': 11, 'european union': 12, 'work and employment': 13, 'health': 14, 'education': 15, 'industry': 16, 'sports': 17}\n"
     ]
    }
   ],
   "source": [
    "test_ds = ClassificationDS(data2, labels2, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ad37cb9-9dd8-4183-a1b3-7c04205235fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'economy': 0, 'law': 1, 'foreign policy': 2, 'agriculture': 3, 'environment': 4, 'social policy': 5, 'state': 6, 'public authorities': 7, 'taxes': 8, 'transport': 9, 'science': 10, 'research and technology': 11, 'european union': 12, 'work and employment': 13, 'health': 14, 'education': 15, 'industry': 16, 'sports': 17}\n"
     ]
    }
   ],
   "source": [
    "train_ds = ClassificationDS(data3, labels3, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a9a6734-9eab-45ca-846a-c1a2f341c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaConfig, RobertaModel, RobertaPreTrainedModel\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c08e734f-7641-4123-81c9-5ca55ee8456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16056ad1-403c-4f5a-9a69-987a67002e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28ad83ea-d0ca-4fbe-a43a-22a0ff2a8593",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRobertaReccurentMemory\u001b[39;00m(RobertaPreTrainedModel):\n\u001b[0;32m      2\u001b[0m     _keys_to_ignore_on_load_missing \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36mRobertaReccurentMemory\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m RobertaClassificationHead(config)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_init()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m---> 16\u001b[0m     input_ids: \u001b[43mOptional\u001b[49m[torch\u001b[38;5;241m.\u001b[39mLongTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m     attention_mask: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m     token_type_ids: Optional[torch\u001b[38;5;241m.\u001b[39mLongTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     19\u001b[0m     position_ids: Optional[torch\u001b[38;5;241m.\u001b[39mLongTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m     head_mask: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m     inputs_embeds: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     labels: Optional[torch\u001b[38;5;241m.\u001b[39mLongTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     24\u001b[0m     output_hidden_states: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m     return_dict: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor], SequenceClassifierOutput]:\n\u001b[0;32m     27\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m     29\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta(\n\u001b[0;32m     30\u001b[0m         input_ids,\n\u001b[0;32m     31\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m     39\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Optional' is not defined"
     ]
    }
   ],
   "source": [
    "class RobertaReccurentMemory(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "\n",
    "        self.post_init()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b31efc57-bcde-4069-b2df-17c53e70d7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/roberta_lm were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../models/roberta_lm and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(notebook_path_prefix, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2477f678-6163-47f9-92ad-74a04e89e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = (pred.predictions >= 0.5).astype(int) #.argmax(-1)\n",
    "    \n",
    "    # print(labels, preds)\n",
    "    \n",
    "    # try:\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    # except ValueError:\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'precision': precision_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'recall': recall_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4350bef4-88f0-4e03-8595-66b0e1adefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "393d8405-3e4d-4117-b221-d71ee50e5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b5efdcc-fe69-4ff1-a973-0b287d3f461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=notebook_path_prefix+\"_classification\",\n",
    "    warmup_steps=500,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=17,\n",
    "    per_device_eval_batch_size=30,\n",
    "    save_steps=5_000,\n",
    "    save_total_limit=3,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    logging_steps=700,\n",
    "    eval_steps=700,\n",
    "    evaluation_strategy='steps',\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"roberta-classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3eb0fac1-a62a-4993-9589-a2eb481a5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_ds,         # training dataset\n",
    "    eval_dataset=dev_ds,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26c6bd7e-5488-4c8d-8391-10b6329d7c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6858\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229/229 17:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7199797034263611,\n",
       " 'eval_accuracy': 0.00014581510644502772,\n",
       " 'eval_f1': 0.0002490339082464446,\n",
       " 'eval_precision': 0.0004896459450760735,\n",
       " 'eval_recall': 0.00019462826002335538,\n",
       " 'eval_runtime': 264.9451,\n",
       " 'eval_samples_per_second': 25.885,\n",
       " 'eval_steps_per_second': 0.864}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1c592ca-0675-4385-b0da-8d052308785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 24003\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 17\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 17\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7060\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7060' max='7060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7060/7060 2:11:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.104666</td>\n",
       "      <td>0.625547</td>\n",
       "      <td>0.678703</td>\n",
       "      <td>0.813450</td>\n",
       "      <td>0.599293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.071193</td>\n",
       "      <td>0.718868</td>\n",
       "      <td>0.812302</td>\n",
       "      <td>0.915701</td>\n",
       "      <td>0.742358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.060752</td>\n",
       "      <td>0.750948</td>\n",
       "      <td>0.840987</td>\n",
       "      <td>0.918501</td>\n",
       "      <td>0.785402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.053062</td>\n",
       "      <td>0.790610</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.926771</td>\n",
       "      <td>0.826159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>0.801108</td>\n",
       "      <td>0.880880</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.844874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.048688</td>\n",
       "      <td>0.808107</td>\n",
       "      <td>0.887665</td>\n",
       "      <td>0.914598</td>\n",
       "      <td>0.865253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.046776</td>\n",
       "      <td>0.821814</td>\n",
       "      <td>0.894140</td>\n",
       "      <td>0.925298</td>\n",
       "      <td>0.867332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.815981</td>\n",
       "      <td>0.892067</td>\n",
       "      <td>0.925757</td>\n",
       "      <td>0.863589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.046144</td>\n",
       "      <td>0.823564</td>\n",
       "      <td>0.896569</td>\n",
       "      <td>0.931438</td>\n",
       "      <td>0.867748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.045806</td>\n",
       "      <td>0.825022</td>\n",
       "      <td>0.896890</td>\n",
       "      <td>0.930830</td>\n",
       "      <td>0.868788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to roberta_lm_classification\\checkpoint-5000\n",
      "Configuration saved in roberta_lm_classification\\checkpoint-5000\\config.json\n",
      "Model weights saved in roberta_lm_classification\\checkpoint-5000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7060, training_loss=0.06947880826320595, metrics={'train_runtime': 7899.7824, 'train_samples_per_second': 15.192, 'train_steps_per_second': 0.894, 'total_flos': 9395897647933440.0, 'train_loss': 0.06947880826320595, 'epoch': 5.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27d89bcd-e565-4d5b-b4b8-58c5199a0f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6858\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='229' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229/229 05:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05427917465567589,\n",
       " 'eval_accuracy': 0.794546515018956,\n",
       " 'eval_f1': 0.8889033891770258,\n",
       " 'eval_precision': 0.9228076499900962,\n",
       " 'eval_recall': 0.8590891397430906,\n",
       " 'eval_runtime': 303.3825,\n",
       " 'eval_samples_per_second': 22.605,\n",
       " 'eval_steps_per_second': 0.755,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc6118-ac87-4b5e-88b6-8bab70caf42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
