{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068b6ea2-432c-4330-829d-94d589f44b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbmarcin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036060f4-b3fe-4499-bd40-31f65f2bce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ds = \"../data/dev/\"\n",
    "test_ds = \"../data/test/\"\n",
    "train_ds = \"../data/train/\"\n",
    "\n",
    "notebook_path_prefix = \"roberta_lm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e9cc7a-c6ec-4eb7-b3b8-5819f4a41a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\n",
    "    '<url>',\n",
    "    '<email>',\n",
    "    '<number>',\n",
    "    '<date>', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3491d32d-c91b-44b6-92b9-fe35aa50a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aabfe31d-51c0-45a8-aae7-77417170a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file roberta_lm/config.json not found\n",
      "file roberta_lm/config.json not found\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(notebook_path_prefix, max_len=512, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a124fcac-eefa-40e4-bf90-47016ff72be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\n",
    "    'additional_special_tokens': special_tokens\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e4ba3d4-0b5c-4f60-8f51-fd96e8d49873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>',\n",
       " 'additional_special_tokens': ['<url>', '<email>', '<number>', '<date>']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ca30b5-3ef5-4fd6-858b-1eb5c69eaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d69e86a-17fc-4bf4-91d2-1f6dd4990142",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../data/dev/in.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "# data2 = pd.read_csv(\"../data/test/in.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")\n",
    "# data3 = pd.read_csv(\"../data/train/in.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2556452-ad64-4260-a30d-ff67e14fac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = pd.read_csv(\"../data/dev/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "# labels2 = pd.read_csv(\"../data/test/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")\n",
    "# labels3 = pd.read_csv(\"../data/train/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b93a7b96-9db4-473b-af65-1fb4c5ea86db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3427 3429\n"
     ]
    }
   ],
   "source": [
    "print(len(data1), len(labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "046e0e18-3d2f-458b-9539-8c43aed67e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>EUROPEAN COMMISSION Brussels, 16.9.2021 COM(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>20.9.2021 EN Official Journal of the European ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>EUROPEAN COMMISSION Brussels, 4.8.2021 COM(202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>EUROPEAN COMMISSION Brussels, 8.9.2021 COM(202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>EUROPEAN COMMISSION Brussels, 20.9.2021 COM(20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "3422  EUROPEAN COMMISSION Brussels, 16.9.2021 COM(20...\n",
       "3423  20.9.2021 EN Official Journal of the European ...\n",
       "3424  EUROPEAN COMMISSION Brussels, 4.8.2021 COM(202...\n",
       "3425  EUROPEAN COMMISSION Brussels, 8.9.2021 COM(202...\n",
       "3426  EUROPEAN COMMISSION Brussels, 20.9.2021 COM(20..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93dc22ad-33ea-4cf1-8152-ead84498c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7e9c199-c48b-4bc1-8244-2b2d8f7b2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = [\n",
    "    'economy',\n",
    "    'law',\n",
    "    'foreign policy',\n",
    "    'agriculture',\n",
    "    'environment',\n",
    "    'social policy',\n",
    "    'state',\n",
    "    'public authorities',\n",
    "    'taxes',\n",
    "    'transport',\n",
    "    'science',\n",
    "    'research and technology',\n",
    "    'european union',\n",
    "    'work and employment',\n",
    "    'health',\n",
    "    'education',\n",
    "    'industry',\n",
    "    'sports'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90311cc5-9080-4c99-9822-1c79fc86ec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'law', 'public authorities', 'state'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set([label.strip().lower() for label in labels1.iloc[1][0].split(',')]); labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eae67904-fbc0-4822-a405-18cd486aeedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_texts, input_labels, unique_labels, tokenizer):\n",
    "        self.input_texts = input_texts\n",
    "        self.input_labels = input_labels\n",
    "        self.unique_labels = unique_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2idx = {}\n",
    "        \n",
    "        for label in self.unique_labels:\n",
    "            self.label2idx[label] = len(self.label2idx)\n",
    "            \n",
    "        print(self.label2idx)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        tokenized = tokenizer(str(self.input_texts.iloc[idx][1]), truncation=True, padding=\"max_length\", max_length=512)\n",
    "        labels = set([self.label2idx[label.strip().lower()] for label in self.input_labels.iloc[idx][0].split(',')])\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': torch.tensor(tokenized['input_ids']),\n",
    "            'attention_mask': torch.tensor(tokenized['attention_mask']),\n",
    "            'labels': torch.zeros([len(self.label2idx)]).index_fill_(0, torch.tensor(list(labels)), 1)\n",
    "        }\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67aef71e-9d37-4dcc-a3f4-9d6aac3e640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'economy': 0, 'law': 1, 'foreign policy': 2, 'agriculture': 3, 'environment': 4, 'social policy': 5, 'state': 6, 'public authorities': 7, 'taxes': 8, 'transport': 9, 'science': 10, 'research and technology': 11, 'european union': 12, 'work and employment': 13, 'health': 14, 'education': 15, 'industry': 16, 'sports': 17}\n"
     ]
    }
   ],
   "source": [
    "dev_ds = ClassificationDS(data1, labels1, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6da6b7c-2089-4f54-802f-de410908d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'economy': 0, 'law': 1, 'foreign policy': 2, 'agriculture': 3, 'environment': 4, 'social policy': 5, 'state': 6, 'public authorities': 7, 'taxes': 8, 'transport': 9, 'science': 10, 'research and technology': 11, 'european union': 12, 'work and employment': 13, 'health': 14, 'education': 15, 'industry': 16, 'sports': 17}\n"
     ]
    }
   ],
   "source": [
    "test_ds = ClassificationDS(data2, labels2, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ad37cb9-9dd8-4183-a1b3-7c04205235fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'economy': 0, 'law': 1, 'foreign policy': 2, 'agriculture': 3, 'environment': 4, 'social policy': 5, 'state': 6, 'public authorities': 7, 'taxes': 8, 'transport': 9, 'science': 10, 'research and technology': 11, 'european union': 12, 'work and employment': 13, 'health': 14, 'education': 15, 'industry': 16, 'sports': 17}\n"
     ]
    }
   ],
   "source": [
    "train_ds = ClassificationDS(data3, labels3, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a9a6734-9eab-45ca-846a-c1a2f341c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c08e734f-7641-4123-81c9-5ca55ee8456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b31efc57-bcde-4069-b2df-17c53e70d7ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file roberta_lm_lm\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 16000\n",
      "}\n",
      "\n",
      "loading weights file roberta_lm_lm\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at roberta_lm_lm were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta_lm_lm and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(notebook_path_prefix+\"_lm\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2477f678-6163-47f9-92ad-74a04e89e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = (pred.predictions >= 0.5).astype(int) #.argmax(-1)\n",
    "    \n",
    "    # print(labels, preds)\n",
    "    \n",
    "    # try:\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    # except ValueError:\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'precision': precision_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'recall': recall_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4350bef4-88f0-4e03-8595-66b0e1adefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "393d8405-3e4d-4117-b221-d71ee50e5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b5efdcc-fe69-4ff1-a973-0b287d3f461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=notebook_path_prefix+\"_classification\",\n",
    "    warmup_steps=500,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=17,\n",
    "    per_device_eval_batch_size=30,\n",
    "    save_steps=5_000,\n",
    "    save_total_limit=3,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    logging_steps=700,\n",
    "    eval_steps=700,\n",
    "    evaluation_strategy='steps',\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"roberta-classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3eb0fac1-a62a-4993-9589-a2eb481a5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_ds,         # training dataset\n",
    "    eval_dataset=dev_ds,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26c6bd7e-5488-4c8d-8391-10b6329d7c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6858\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='344' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229/229 17:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7199797034263611,\n",
       " 'eval_accuracy': 0.00014581510644502772,\n",
       " 'eval_f1': 0.0002490339082464446,\n",
       " 'eval_precision': 0.0004896459450760735,\n",
       " 'eval_recall': 0.00019462826002335538,\n",
       " 'eval_runtime': 264.9451,\n",
       " 'eval_samples_per_second': 25.885,\n",
       " 'eval_steps_per_second': 0.864}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1c592ca-0675-4385-b0da-8d052308785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 24003\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 17\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 17\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7060\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7060' max='7060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7060/7060 2:11:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.104666</td>\n",
       "      <td>0.625547</td>\n",
       "      <td>0.678703</td>\n",
       "      <td>0.813450</td>\n",
       "      <td>0.599293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.071193</td>\n",
       "      <td>0.718868</td>\n",
       "      <td>0.812302</td>\n",
       "      <td>0.915701</td>\n",
       "      <td>0.742358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.060752</td>\n",
       "      <td>0.750948</td>\n",
       "      <td>0.840987</td>\n",
       "      <td>0.918501</td>\n",
       "      <td>0.785402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.053062</td>\n",
       "      <td>0.790610</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.926771</td>\n",
       "      <td>0.826159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>0.801108</td>\n",
       "      <td>0.880880</td>\n",
       "      <td>0.925592</td>\n",
       "      <td>0.844874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.048688</td>\n",
       "      <td>0.808107</td>\n",
       "      <td>0.887665</td>\n",
       "      <td>0.914598</td>\n",
       "      <td>0.865253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.046776</td>\n",
       "      <td>0.821814</td>\n",
       "      <td>0.894140</td>\n",
       "      <td>0.925298</td>\n",
       "      <td>0.867332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.815981</td>\n",
       "      <td>0.892067</td>\n",
       "      <td>0.925757</td>\n",
       "      <td>0.863589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.046144</td>\n",
       "      <td>0.823564</td>\n",
       "      <td>0.896569</td>\n",
       "      <td>0.931438</td>\n",
       "      <td>0.867748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.045806</td>\n",
       "      <td>0.825022</td>\n",
       "      <td>0.896890</td>\n",
       "      <td>0.930830</td>\n",
       "      <td>0.868788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to roberta_lm_classification\\checkpoint-5000\n",
      "Configuration saved in roberta_lm_classification\\checkpoint-5000\\config.json\n",
      "Model weights saved in roberta_lm_classification\\checkpoint-5000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3429\n",
      "  Batch size = 30\n",
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7060, training_loss=0.06947880826320595, metrics={'train_runtime': 7899.7824, 'train_samples_per_second': 15.192, 'train_steps_per_second': 0.894, 'total_flos': 9395897647933440.0, 'train_loss': 0.06947880826320595, 'epoch': 5.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27d89bcd-e565-4d5b-b4b8-58c5199a0f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6858\n",
      "  Batch size = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='229' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229/229 05:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\PetraRQ2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05427917465567589,\n",
       " 'eval_accuracy': 0.794546515018956,\n",
       " 'eval_f1': 0.8889033891770258,\n",
       " 'eval_precision': 0.9228076499900962,\n",
       " 'eval_recall': 0.8590891397430906,\n",
       " 'eval_runtime': 303.3825,\n",
       " 'eval_samples_per_second': 22.605,\n",
       " 'eval_steps_per_second': 0.755,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc6118-ac87-4b5e-88b6-8bab70caf42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
