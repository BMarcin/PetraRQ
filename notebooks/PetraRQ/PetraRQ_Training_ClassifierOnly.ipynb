{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2ba595-106f-4cf8-94af-8e359905b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb38c629-8a6c-48c4-9004-74a15c213cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CyclicLR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833e8222-2f9a-41a0-97a6-c8aafc2680b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7e76b6-9b9b-4dbb-b9ad-8a9b324c8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor, TQDMProgressBar, StochasticWeightAveraging\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import logging\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from src.PetraRQ.PetraRQDatasets import LanguageModellingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a058c852-a8a4-4404-980f-92726856f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ca7611-1395-49c2-b2cc-db0b2027fcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(1, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50c95b2-c264-4d18-b5f5-20bc66a6c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -  %(message)s',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb66c2b7-4dee-450c-b808-fb0ca64e1cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../../data/train/processed.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "data_dev = pd.read_csv(\"../../data/dev/processed.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "labels_train = pd.read_csv(\"../../data/train/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "labels_dev = pd.read_csv(\"../../data/dev/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa11eda-fcba-4921-b1f2-47c0cac5a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels_tsv = pd.read_csv(\"../../data/labels.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "unique_labels = unique_labels_tsv[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01142302-83c5-4718-8dd8-5c2e42485057",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 2\n",
    "dev_batch_size = 6\n",
    "shuffle = False\n",
    "steps = 4000\n",
    "d_model = 512\n",
    "num_tokens = 8000\n",
    "seq_length = 512\n",
    "overlapping_part = 256\n",
    "depth = 4\n",
    "# k = 256\n",
    "heads = 8\n",
    "# dim_head = None\n",
    "# one_kv_head = False\n",
    "# share_kv = True\n",
    "dropout = 0.1\n",
    "optimizer = \"adagrad\"\n",
    "lr_min=1e-5\n",
    "lr_max=3e-4\n",
    "accumulate_grad_batches=6\n",
    "# duplicate_dataset_ratio=1\n",
    "# inputs_masking = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61894b3-459b-4ad1-b456-8eefe8fa0f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_texts, input_labels, unique_labels, tokenizer):\n",
    "        self.input_texts = input_texts\n",
    "        self.input_labels = input_labels\n",
    "        self.unique_labels = unique_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2idx = {}\n",
    "\n",
    "        # self.bp = BasicProcessor()\n",
    "\n",
    "        for label in self.unique_labels:\n",
    "            self.label2idx[label] = len(self.label2idx)\n",
    "\n",
    "        print(self.label2idx)\n",
    "\n",
    "#         self.tokenized_texts = []\n",
    "\n",
    "\n",
    "#         for idx in tqdm(range(len(self.input_texts)), desc='Tokenizing texts'):\n",
    "#             tokenized = self.tokenizer.encode(self.input_texts.iloc[idx][0])\n",
    "#             self.tokenized_texts.append(tokenized)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def labels2tensor(self, labels):\n",
    "        return set([self.label2idx[label.strip().lower()] for label in labels])\n",
    "\n",
    "    def tensor2labels(self, tensor):\n",
    "        labels = []\n",
    "        for idx, label in enumerate(self.unique_labels):\n",
    "            if tensor[idx] == 1:\n",
    "                labels.append(label)\n",
    "        return labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokenized = self.tokenizer.encode(self.input_texts.iloc[idx][0])\n",
    "        labels = self.labels2tensor(self.input_labels.iloc[idx][0].split(' '))\n",
    "\n",
    "        # item = {\n",
    "        #     'input_ids': torch.tensor(tokenized['input_ids']),\n",
    "        #     'attention_mask': torch.tensor(tokenized['attention_mask']),\n",
    "        #     'labels': torch.zeros([len(self.label2idx)]).index_fill_(0, torch.tensor(list(labels)), 1)\n",
    "        # }\n",
    "\n",
    "        return np.array(tokenized.ids), torch.zeros([len(self.label2idx)]).index_fill_(0, torch.tensor(list(labels)), 1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dedeb89-2dbf-4a1c-8999-51de5e5a7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"./tokenizer_{}.json\".format(\"3ded16b3953922cceaa90923883a7147\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17628537-7b07-4c38-a856-998a87e6e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'health': 0, 'media_informations': 1, 'transportation': 2, 'industry': 3, 'work_and_employment': 4, 'agriculture': 5, 'social_life': 6, 'internal_security': 7, 'economy': 8, 'environment': 9, 'european_union': 10, 'energy': 11, 'foreign_policy': 12, 'education': 13, 'law': 14, 'politics_political_parties': 15, 'sports': 16, 'research_science_and_technology': 17, 'taxes': 18}\n",
      "{'health': 0, 'media_informations': 1, 'transportation': 2, 'industry': 3, 'work_and_employment': 4, 'agriculture': 5, 'social_life': 6, 'internal_security': 7, 'economy': 8, 'environment': 9, 'european_union': 10, 'energy': 11, 'foreign_policy': 12, 'education': 13, 'law': 14, 'politics_political_parties': 15, 'sports': 16, 'research_science_and_technology': 17, 'taxes': 18}\n"
     ]
    }
   ],
   "source": [
    "dev_ds = ClassificationDataset(data_dev, labels_dev, unique_labels, tokenizer)\n",
    "train_ds = ClassificationDataset(data_train, labels_train, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b520f394-f243-4de5-a3ae-c64aaaab540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coll_fn(batch):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    incremental_indexes = []\n",
    "    \n",
    "    pad_token = 2\n",
    "    \n",
    "    for (text, label) in batch:\n",
    "        texts.append(torch.tensor(text).to(\"cpu\"))\n",
    "        labels.append(label)\n",
    "\n",
    "    ins = nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=pad_token)\n",
    "    seq_len = ins.shape[1]\n",
    "    \n",
    "    rest = seq_len % seq_length\n",
    "    # print(seq_len, 256 - rest)\n",
    "    if rest != 0:\n",
    "        fill_matrix = torch.zeros((ins.shape[0], seq_length - rest)).fill_(pad_token).long()\n",
    "        ins = torch.cat((ins, fill_matrix), dim=1)\n",
    "\n",
    "    return ins.numpy(), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d194bc8-bf7e-4ad1-aa7f-e9bef83faef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    collate_fn=coll_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85fb2daa-dfef-41ca-ba4d-0e1bb8edb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_loader = DataLoader(\n",
    "    dev_ds,\n",
    "    batch_size=dev_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    collate_fn=coll_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ff0aae-a764-4ad3-8e03-98187d24129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 644 4129   32 ...    2    2    2]\n",
      " [5667 5677 1324 ...    2    2    2]\n",
      " [5667 5677 1324 ...    2    2    2]\n",
      " [5667 5677 1324 ...    2    2    2]\n",
      " [5667 5677 1324 ...    2    2    2]\n",
      " [5667 5677 1324 ...    2    2    2]] [[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]] (6, 4096) (6, 19)\n"
     ]
    }
   ],
   "source": [
    "for (x, y) in dev_data_loader:\n",
    "    print(x, y, x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a12bf44c-488a-40c4-8aae-64e0a5b87cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    # print(preds.shape, preds)\n",
    "    preds = (preds >= 0.5).astype(int)#.argmax(-1)\n",
    "\n",
    "    # print(preds.shape, labels.shape)\n",
    "    # print(preds, labels)\n",
    "\n",
    "    # try:\n",
    "    acc = accuracy_score(preds, labels)\n",
    "    # except ValueError:\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'precision': precision_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'recall': recall_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb2a796f-1e52-40bd-9f4e-fadb4333d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 50000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "154984c8-78a1-4213-8073-0da9ee8a79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetraRQ(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            d_model,\n",
    "            num_labels,\n",
    "            seq_length,\n",
    "            overlapping_part,\n",
    "            depth,\n",
    "            heads=8,\n",
    "            dropout=0.1,\n",
    "            steps=1000,\n",
    "            lr_min=1e-4,\n",
    "            lr_max=3e-3,\n",
    "            optim=\"adam\"\n",
    "    ):\n",
    "        super(PetraRQ, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_labels = num_labels\n",
    "        self.seq_length = seq_length\n",
    "        self.overlapping_part = overlapping_part\n",
    "        self.depth = depth\n",
    "        self.heads = heads\n",
    "        self.dropout = dropout\n",
    "        self.steps = steps\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_max = lr_max\n",
    "        self.optim = optim\n",
    "        self.overlapping_part = overlapping_part\n",
    "        self.activation = nn.GELU()\n",
    "        self.out_norm = nn.LayerNorm(d_model)\n",
    "        self.memory_norm = nn.LayerNorm(d_model)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "        assert (self.optim == 'adam' or self.optim == 'adagrad'), 'Optim must be set to \"adam\" or \"adagrad\"'\n",
    "\n",
    "        self.token_emb = nn.Embedding(num_tokens, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        \n",
    "        self.former_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=heads)\n",
    "        self.former = nn.TransformerEncoder(self.former_layer, num_layers=depth)\n",
    "        \n",
    "        self.to_logits = nn.Linear(d_model, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        floating_memory = None\n",
    "        output_hidden_layers = None\n",
    "        floating_mems = None\n",
    "        \n",
    "        # print('x_in', x_in.shape)\n",
    "        \n",
    "        i = 0\n",
    "        while ((output_hidden_layers is None) or (output_hidden_layers + (x_in.shape[1] % self.overlapping_part) < x_in.shape[1])):\n",
    "        \n",
    "            if floating_memory is None:\n",
    "                x = self.token_emb(x_in[:, :self.seq_length].to(self.device))\n",
    "                x_pos = self.pos_emb(x)\n",
    "            else:\n",
    "                part = self.seq_length / self.overlapping_part\n",
    "                toks = x_in[:, int((self.overlapping_part * (i+part-1))):int((self.overlapping_part * (i+part)))].to(self.device)\n",
    "                # print('from', int((self.overlapping_part * (i+part-1))), 'to', int((self.overlapping_part * (i+part))))\n",
    "                embeds = self.token_emb(toks)\n",
    "                x_pos = self.pos_emb(embeds)\n",
    "                x_pos = torch.cat((x[:, self.overlapping_part:, :], x_pos), dim=1)\n",
    "                \n",
    "            # print('x_pos', x_pos.shape)\n",
    "            # if output_hidden_layers is not None:\n",
    "                # print('dzialanie', output_hidden_layers + (x_in.shape[1] % self.overlapping_part), x_in.shape)\n",
    "            x = self.former(x_pos)\n",
    "            \n",
    "            if floating_memory is None:\n",
    "                floating_memory = x[:, :self.overlapping_part, :]\n",
    "                output_hidden_layers = overlapping_part\n",
    "                # output_hidden_layers = x[:, :self.overlapping_part, :]\n",
    "                # floating_mems = x_pos[:, :self.overlapping_part, :]\n",
    "            else:\n",
    "                add = floating_memory + x[:, :self.overlapping_part, :]\n",
    "                floating_memory = self.memory_norm(add)\n",
    "                output_hidden_layers += self.overlapping_part\n",
    "                # output_hidden_layers = torch.cat((output_hidden_layers, x[:, :self.overlapping_part, :]), dim=1)\n",
    "                # floating_mems = torch.cat((floating_mems, floating_memory), dim=1)\n",
    "            del(x_pos)\n",
    "            i += 1\n",
    "\n",
    "        out = torch.cat((floating_memory, x[:, self.overlapping_part:, :]), dim=1)\n",
    "\n",
    "        # print(out.shape)\n",
    "        # out = out[:, 0, :]\n",
    "        out = out.sum(dim=1)\n",
    "        out = self.out_norm(out)\n",
    "        out = self.to_logits(out)\n",
    "        out = self.sigm(out)\n",
    "        # out = self.out_norm(out)\n",
    "        # out = torch.tanh(out)\n",
    "        # out = (out >= 0.5).long()\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optim == 'adagrad':\n",
    "            optimizer = torch.optim.Adagrad(\n",
    "                self.parameters(),\n",
    "                lr=self.lr_min,\n",
    "                weight_decay=0.01\n",
    "            )\n",
    "        elif self.optim == 'adam':\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(),\n",
    "                lr=self.lr_min,\n",
    "                weight_decay=0.01,\n",
    "                betas=(0.9, 0.999)\n",
    "            )\n",
    "\n",
    "        lr_scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.lr_max,\n",
    "            total_steps=self.steps,\n",
    "            cycle_momentum=False,\n",
    "        )\n",
    "\n",
    "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
    "        # return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        x = torch.tensor(xs).to(\"cpu\")\n",
    "        y = torch.tensor(ys).to(self.device)\n",
    "        \n",
    "        x = self.forward(x)        \n",
    "\n",
    "        loss = F.binary_cross_entropy(x, y)\n",
    "        \n",
    "        metrics = compute_metrics(x.detach().cpu().numpy(), y.long().detach().cpu().numpy())\n",
    "        \n",
    "        self.log('train/f1', metrics['f1'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('train/accuracy', metrics['accuracy'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('train/precision', metrics['precision'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('train/recall', metrics['recall'], prog_bar=True, batch_size=x.shape[0])\n",
    "\n",
    "        self.log('train/loss', loss, prog_bar=True, batch_size=x.shape[0])\n",
    "        return {\n",
    "            'loss': loss, \n",
    "            'train_f1': metrics['f1'],\n",
    "            'train_acc': metrics['accuracy'],\n",
    "            'train_precision': metrics['precision'],\n",
    "            'train_recall': metrics['recall']\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        x = torch.tensor(xs).to(\"cpu\")\n",
    "        y = torch.tensor(ys).to(self.device)\n",
    "        \n",
    "        x = self.forward(x)        \n",
    "\n",
    "        loss = F.binary_cross_entropy(x, y)\n",
    "        \n",
    "        metrics = compute_metrics(x.cpu().numpy(), y.long().cpu().numpy())\n",
    "        \n",
    "        self.log('eval/f1', metrics['f1'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('eval/accuracy', metrics['accuracy'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('eval/precision', metrics['precision'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('eval/recall', metrics['recall'], prog_bar=True, batch_size=x.shape[0])\n",
    "\n",
    "        self.log('eval/loss', loss, prog_bar=True, batch_size=x.shape[0])\n",
    "        return {\n",
    "            'val_loss': loss, \n",
    "            'val_f1': metrics['f1'],\n",
    "            'val_acc': metrics['accuracy'],\n",
    "            'val_precision': metrics['precision'],\n",
    "            'val_recall': metrics['recall']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e42dfe42-6d42-4ea7-b49a-793803b23e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "petra = PetraRQ(\n",
    "    d_model=d_model,\n",
    "    num_labels=len(unique_labels),\n",
    "    seq_length=seq_length,\n",
    "    overlapping_part=overlapping_part,\n",
    "    depth=depth,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    steps=steps,\n",
    "    optim=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22814f49-d52c-41c7-bbc4-2cf8ff5acf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 17:56:14,242 - ERROR - wandb.jupyter -  Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: bmarcin. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Praca\\PetraRQ2\\PetraRQ\\notebooks\\PetraRQ\\wandb\\run-20220816_175617-3i1y0xqu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/bmarcin/PetraRQ/runs/3i1y0xqu\" target=\"_blank\">PetraRQ_classifier_recurrent_transfomer</a></strong> to <a href=\"https://wandb.ai/bmarcin/PetraRQ\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    project=\"PetraRQ\",\n",
    "    name=\"PetraRQ_classifier_recurrent_transfomer\",\n",
    "    log_model=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c634e7ec-8dbc-46fe-a431-c0373e1cae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger.experiment.config['batch_size'] = train_batch_size\n",
    "wandb_logger.experiment.config['steps'] = steps\n",
    "wandb_logger.experiment.config['d_model'] = d_model\n",
    "wandb_logger.experiment.config['num_labels'] = len(unique_labels)\n",
    "wandb_logger.experiment.config['seq_length'] = seq_length\n",
    "wandb_logger.experiment.config['depth'] = depth\n",
    "wandb_logger.experiment.config['heads'] = heads\n",
    "wandb_logger.experiment.config['dropout'] = dropout\n",
    "wandb_logger.experiment.config['optimizer'] = optimizer\n",
    "# wandb_logger.experiment.config['duplicate_dataset_ratio'] = duplicate_dataset_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afcfc6b5-dd19-4e15-b903-45e4cded1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    devices=1,\n",
    "    max_steps=steps,\n",
    "    log_every_n_steps=5,\n",
    "    accelerator='gpu',\n",
    "    # accumulate_grad_batches=accumulate_grad_batches,\n",
    "    val_check_interval=0.05,\n",
    "    # val_check_interval=300,\n",
    "    default_root_dir='./PetraRQmodel',\n",
    "    enable_checkpointing=False,\n",
    "    callbacks=[\n",
    "        # ModelCheckpoint(\n",
    "        #     dirpath='./PetraRQmodel/checkpoints',\n",
    "        #     save_top_k=3,\n",
    "        #     monitor='eval/loss',\n",
    "        #     mode='min',\n",
    "        #     filename='petrarq-{epoch}-{val_loss:.2f}.ckpt'\n",
    "        # ),\n",
    "        EarlyStopping(\n",
    "            monitor='eval/f1',\n",
    "            mode='min',\n",
    "            patience=4,\n",
    "            check_finite=True,\n",
    "        ),\n",
    "        LearningRateMonitor(logging_interval='step'),\n",
    "        TQDMProgressBar(refresh_rate=1),\n",
    "        # StochasticWeightAveraging(swa_lrs=1e-3)\n",
    "    ],\n",
    "    logger=wandb_logger,\n",
    "    reload_dataloaders_every_n_epochs=0,\n",
    "    gradient_clip_val=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b15cd5ff-77db-4855-9c22-e723957d6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51273443-3d2c-4c2d-b046-c1d731669e64",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "D:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d7c35a85b94e8d893413fc8d5b78f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.validate(petra, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1258080e-1203-4680-9784-01891d2bcbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                    | Params\n",
      "---------------------------------------------------------\n",
      "0 | activation   | GELU                    | 0     \n",
      "1 | out_norm     | LayerNorm               | 1.0 K \n",
      "2 | memory_norm  | LayerNorm               | 1.0 K \n",
      "3 | sigm         | Sigmoid                 | 0     \n",
      "4 | token_emb    | Embedding               | 4.1 M \n",
      "5 | pos_emb      | PositionalEncoding      | 0     \n",
      "6 | former_layer | TransformerEncoderLayer | 3.2 M \n",
      "7 | former       | TransformerEncoder      | 12.6 M\n",
      "8 | to_logits    | Linear                  | 9.7 K \n",
      "---------------------------------------------------------\n",
      "19.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.9 M    Total params\n",
      "79.479    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7af64d0ff2478fb3ec765e97acbd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[0;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    810\u001b[0m )\n\u001b[1;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1236\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1236\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1238\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1323\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1345\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1413\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1413\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 155\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:128\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    129\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:226\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1765\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1765\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:344\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mPetraRQ.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    152\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(ys)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 154\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[0;32m    156\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(x, y)\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mPetraRQ.forward\u001b[1;34m(self, x_in)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# print('x_pos', x_pos.shape)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# if output_hidden_layers is not None:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# print('dzialanie', output_hidden_layers + (x_in.shape[1] % self.overlapping_part), x_in.shape)\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m floating_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:238\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:463\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    464\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:471\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[0;32m    470\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 471\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1153\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1153\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\functional.py:5066\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5065\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 5066\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\torch\\nn\\functional.py:4745\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[1;34m(q, k, v, w, b)\u001b[0m\n\u001b[0;32m   4743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[0;32m   4744\u001b[0m     \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[1;32m-> 4745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4747\u001b[0m     \u001b[38;5;66;03m# encoder-decoder attention\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpetra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_data_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:738\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mreconciliate_processes(traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exception)\n\u001b[1;32m--> 738\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1300\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;124;03mCallback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_dispatch(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1300\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1301\u001b[0m loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\strategies\\single_device.py:93\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;66;03m# GPU teardown\u001b[39;00m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:444\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;124;03m\"\"\"This method is called to teardown the training process.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03m    It is the right place to release memory and free other resources.\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m     \u001b[43moptimizers_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\utilities\\optimizer.py:27\u001b[0m, in \u001b[0;36moptimizers_to_device\u001b[1;34m(optimizers, device)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"Moves optimizer states for a sequence of optimizers to the device.\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m opt \u001b[38;5;129;01min\u001b[39;00m optimizers:\n\u001b[1;32m---> 27\u001b[0m     \u001b[43moptimizer_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\utilities\\optimizer.py:33\u001b[0m, in \u001b[0;36moptimizer_to_device\u001b[1;34m(optimizer, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"Moves the state of a single optimizer to the device.\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p, v \u001b[38;5;129;01min\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 33\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstate[p] \u001b[38;5;241m=\u001b[39m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove_data_to_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:107\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 107\u001b[0m     v \u001b[38;5;241m=\u001b[39m apply_to_collection(\n\u001b[0;32m    108\u001b[0m         v, dtype, function, \u001b[38;5;241m*\u001b[39margs, wrong_dtype\u001b[38;5;241m=\u001b[39mwrong_dtype, include_none\u001b[38;5;241m=\u001b[39minclude_none, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    109\u001b[0m     )\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_none \u001b[38;5;129;01mor\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend((k, v))\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:99\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Breaking condition\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype) \u001b[38;5;129;01mand\u001b[39;00m (wrong_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    101\u001b[0m elem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(data)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Recursively apply to collection items\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:354\u001b[0m, in \u001b[0;36mmove_data_to_device\u001b[1;34m(batch, device)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m    353\u001b[0m dtype \u001b[38;5;241m=\u001b[39m (TransferableDataType, Batch) \u001b[38;5;28;01mif\u001b[39;00m _TORCHTEXT_LEGACY \u001b[38;5;28;01melse\u001b[39;00m TransferableDataType\n\u001b[1;32m--> 354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:99\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Breaking condition\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype) \u001b[38;5;129;01mand\u001b[39;00m (wrong_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    101\u001b[0m elem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(data)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Recursively apply to collection items\u001b[39;00m\n",
      "File \u001b[1;32mD:\\PetraRQ\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:347\u001b[0m, in \u001b[0;36mmove_data_to_device.<locals>.batch_to\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _CPU_DEVICES:\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_blocking\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m data_output \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_output\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer.fit(petra, train_data_loader, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42969c-d6cb-4355-b9f7-c9fcb2084c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
