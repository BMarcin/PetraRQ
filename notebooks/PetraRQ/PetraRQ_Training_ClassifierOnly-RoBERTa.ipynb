{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2ba595-106f-4cf8-94af-8e359905b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb38c629-8a6c-48c4-9004-74a15c213cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CyclicLR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833e8222-2f9a-41a0-97a6-c8aafc2680b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7e76b6-9b9b-4dbb-b9ad-8a9b324c8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor, TQDMProgressBar, StochasticWeightAveraging\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import logging\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from src.PetraRQ.PetraRQDatasets import LanguageModellingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a058c852-a8a4-4404-980f-92726856f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ca7611-1395-49c2-b2cc-db0b2027fcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(1, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50c95b2-c264-4d18-b5f5-20bc66a6c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -  %(message)s',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d141350a-9383-4136-aef1-240212a24c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ds = \"../data/dev/\"\n",
    "test_ds = \"../data/test/\"\n",
    "train_ds = \"../data/train/\"\n",
    "\n",
    "lm_model_path = \"../../models/roberta_lm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a489d97-7aa8-4912-b1c0-84389b8d39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\n",
    "    '<url>',\n",
    "    '<email>',\n",
    "    '<number>',\n",
    "    '<date>', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18fd8dac-ab5e-4636-8657-2f210beb09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f318562a-cab1-40a5-859b-1458ebc26ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(lm_model_path, max_len=512, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d654c19-d1a1-4da3-a7bb-99946d09d260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\n",
    "    'additional_special_tokens': special_tokens\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c2574b-11de-4d1d-a5ef-35d47f27bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>',\n",
       " 'additional_special_tokens': ['<url>', '<email>', '<number>', '<date>']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb66c2b7-4dee-450c-b808-fb0ca64e1cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../../data/train/processed.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "data_dev = pd.read_csv(\"../../data/dev/processed.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "labels_train = pd.read_csv(\"../../data/train/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "labels_dev = pd.read_csv(\"../../data/dev/expected.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfa11eda-fcba-4921-b1f2-47c0cac5a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels_tsv = pd.read_csv(\"../../data/labels.tsv\", delimiter='\\t', header=None, encoding=\"utf8\", quoting=0)\n",
    "unique_labels = unique_labels_tsv[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8ceca91-a222-4940-b89a-6eb5fad803d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30ec28e7-c581-490f-a9b2-4c1cffc87858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../models/roberta_lm were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../../models/roberta_lm and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(lm_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebc0fe6a-db58-4544-9c66-cf78826f8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f8a627-f6a3-4eb6-b0fe-5fdc467adf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.ones(2, 512).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b6b6758-3041-4f2a-b6eb-70080c27741d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         ...,\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089]],\n",
       "\n",
       "        [[-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         ...,\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089],\n",
       "         [-1.2255,  0.8372,  1.3041,  ...,  0.1445,  0.3960, -2.3089]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t1).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af01037a-d23e-46b6-919e-d3a5ee748d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01142302-83c5-4718-8dd8-5c2e42485057",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 768\n",
    "train_batch_size = 12\n",
    "dev_batch_size = 6\n",
    "shuffle = False\n",
    "steps = 4000\n",
    "seq_length = 512\n",
    "overlapping_part = 256\n",
    "dropout = 0.1\n",
    "optimizer = \"adam\"\n",
    "lr_min=3e-4\n",
    "lr_max=3e-3\n",
    "accumulate_grad_batches=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b61894b3-459b-4ad1-b456-8eefe8fa0f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_texts, input_labels, unique_labels, tokenizer):\n",
    "        self.input_texts = input_texts\n",
    "        self.input_labels = input_labels\n",
    "        self.unique_labels = unique_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2idx = {}\n",
    "\n",
    "        # self.bp = BasicProcessor()\n",
    "\n",
    "        for label in self.unique_labels:\n",
    "            self.label2idx[label] = len(self.label2idx)\n",
    "\n",
    "        print(self.label2idx)\n",
    "\n",
    "#         self.tokenized_texts = []\n",
    "\n",
    "\n",
    "#         for idx in tqdm(range(len(self.input_texts)), desc='Tokenizing texts'):\n",
    "#             tokenized = self.tokenizer.encode(self.input_texts.iloc[idx][0])\n",
    "#             self.tokenized_texts.append(tokenized)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def labels2tensor(self, labels):\n",
    "        return set([self.label2idx[label.strip().lower()] for label in labels])\n",
    "\n",
    "    def tensor2labels(self, tensor):\n",
    "        labels = []\n",
    "        for idx, label in enumerate(self.unique_labels):\n",
    "            if tensor[idx] == 1:\n",
    "                labels.append(label)\n",
    "        return labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokenized = self.tokenizer.encode(self.input_texts.iloc[idx][0])\n",
    "        labels = self.labels2tensor(self.input_labels.iloc[idx][0].split(' '))\n",
    "\n",
    "        # item = {\n",
    "        #     'input_ids': torch.tensor(tokenized['input_ids']),\n",
    "        #     'attention_mask': torch.tensor(tokenized['attention_mask']),\n",
    "        #     'labels': torch.zeros([len(self.label2idx)]).index_fill_(0, torch.tensor(list(labels)), 1)\n",
    "        # }\n",
    "        return np.array(tokenized), torch.zeros([len(self.label2idx)]).index_fill_(0, torch.tensor(list(labels)), 1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17628537-7b07-4c38-a856-998a87e6e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'health': 0, 'media_informations': 1, 'transportation': 2, 'industry': 3, 'work_and_employment': 4, 'agriculture': 5, 'social_life': 6, 'internal_security': 7, 'economy': 8, 'environment': 9, 'european_union': 10, 'energy': 11, 'foreign_policy': 12, 'education': 13, 'law': 14, 'politics_political_parties': 15, 'sports': 16, 'research_science_and_technology': 17, 'taxes': 18}\n",
      "{'health': 0, 'media_informations': 1, 'transportation': 2, 'industry': 3, 'work_and_employment': 4, 'agriculture': 5, 'social_life': 6, 'internal_security': 7, 'economy': 8, 'environment': 9, 'european_union': 10, 'energy': 11, 'foreign_policy': 12, 'education': 13, 'law': 14, 'politics_political_parties': 15, 'sports': 16, 'research_science_and_technology': 17, 'taxes': 18}\n"
     ]
    }
   ],
   "source": [
    "dev_ds = ClassificationDataset(data_dev, labels_dev, unique_labels, tokenizer)\n",
    "train_ds = ClassificationDataset(data_train, labels_train, unique_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b520f394-f243-4de5-a3ae-c64aaaab540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coll_fn(batch):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    incremental_indexes = []\n",
    "    \n",
    "    pad_token = 5\n",
    "    \n",
    "    for (text, label) in batch:\n",
    "        texts.append(torch.tensor(text).to(\"cpu\"))\n",
    "        labels.append(label)\n",
    "\n",
    "    ins = nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=pad_token)[:, :5120]\n",
    "    seq_len = ins.shape[1]\n",
    "    \n",
    "    rest = seq_len % seq_length\n",
    "    # print(seq_len, 256 - rest)\n",
    "    if rest != 0:\n",
    "        fill_matrix = torch.zeros((ins.shape[0], seq_length - rest)).fill_(pad_token).long()\n",
    "        ins = torch.cat((ins, fill_matrix), dim=1)\n",
    "\n",
    "    return ins.numpy(), np.array(labels), (~(ins == 5)).long().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d194bc8-bf7e-4ad1-aa7f-e9bef83faef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    collate_fn=coll_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85fb2daa-dfef-41ca-ba4d-0e1bb8edb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_loader = DataLoader(\n",
    "    dev_ds,\n",
    "    batch_size=dev_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    collate_fn=coll_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3ff0aae-a764-4ad3-8e03-98187d24129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3481 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    4 15916 12987 ...     5     5     5]\n",
      " [    4  3364  3348 ...     5     5     5]\n",
      " [    4  3364  3348 ...     5     5     5]\n",
      " [    4  3364  3348 ...     5     5     5]\n",
      " [    4  3364  3348 ...     5     5     5]\n",
      " [    4  3364  3348 ...     5     5     5]] [[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]] [[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]] (6, 3584) (6, 19) (6, 3584)\n"
     ]
    }
   ],
   "source": [
    "for (x, y, att) in dev_data_loader:\n",
    "    print(x, y, att, x.shape, y.shape, att.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a12bf44c-488a-40c4-8aae-64e0a5b87cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    # print(preds.shape, preds)\n",
    "    preds = (preds >= 0.5).astype(int)#.argmax(-1)\n",
    "\n",
    "    # print(preds.shape, labels.shape)\n",
    "    # print(preds, labels)\n",
    "\n",
    "    # try:\n",
    "    acc = accuracy_score(preds, labels)\n",
    "    # except ValueError:\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'precision': precision_score(y_true=labels, y_pred=preds, average='weighted'),\n",
    "        'recall': recall_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "154984c8-78a1-4213-8073-0da9ee8a79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetraRQ(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            d_model,\n",
    "            embeddings,\n",
    "            model,\n",
    "            num_labels,\n",
    "            seq_length,\n",
    "            overlapping_part,\n",
    "            steps=1000,\n",
    "            lr_min=1e-4,\n",
    "            lr_max=3e-3,\n",
    "            optim=\"adam\"\n",
    "    ):\n",
    "        super(PetraRQ, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_labels = num_labels\n",
    "        self.seq_length = seq_length\n",
    "        self.overlapping_part = overlapping_part\n",
    "        self.steps = steps\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_max = lr_max\n",
    "        self.optim = optim\n",
    "        self.overlapping_part = overlapping_part\n",
    "        self.memory_norm = nn.LayerNorm(d_model)\n",
    "        self.out_norm = nn.LayerNorm(d_model)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "        assert (self.optim == 'adam' or self.optim == 'adagrad'), 'Optim must be set to \"adam\" or \"adagrad\"'\n",
    "\n",
    "        self.embeds = embeddings\n",
    "        self.roberta = model\n",
    "        \n",
    "        self.to_logits = nn.Linear(d_model, num_labels)\n",
    "        \n",
    "        for param in self.roberta.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in self.embeds.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x_in, attention):\n",
    "        floating_memory = None\n",
    "        output_hidden_layers = None\n",
    "        floating_mems = None\n",
    "        \n",
    "        # print('x_in', x_in.shape)\n",
    "        \n",
    "        i = 0\n",
    "        while ((output_hidden_layers is None) or (output_hidden_layers + (x_in.shape[1] % self.overlapping_part) < x_in.shape[1])):\n",
    "            part = self.seq_length / self.overlapping_part\n",
    "            if floating_memory is None:\n",
    "                x_pos = self.embeds(x_in[:, :self.seq_length].to(self.device))\n",
    "            else:\n",
    "                toks = x_in[:, int((self.overlapping_part * (i+part-1))):int((self.overlapping_part * (i+part)))].to(self.device)\n",
    "                # print('from', int((self.overlapping_part * (i+part-1))), 'to', int((self.overlapping_part * (i+part))))\n",
    "                x_pos = self.embeds(toks)\n",
    "                x_pos = torch.cat((x[:, self.overlapping_part:, :], x_pos), dim=1)\n",
    "                \n",
    "            # print('x_pos', x_pos.shape)\n",
    "            # if output_hidden_layers is not None:\n",
    "                # print('dzialanie', output_hidden_layers + (x_in.shape[1] % self.overlapping_part), x_in.shape)\n",
    "            att_part = attention[:, self.overlapping_part*i:(self.overlapping_part*i) + self.seq_length].to(self.device)\n",
    "            # print(att_part.shape)\n",
    "            x = self.roberta(inputs_embeds=x_pos, attention_mask=att_part).last_hidden_state\n",
    "            \n",
    "            if floating_memory is None:\n",
    "                floating_memory = x[:, :self.overlapping_part, :]\n",
    "                output_hidden_layers = overlapping_part\n",
    "                # output_hidden_layers = x[:, :self.overlapping_part, :]\n",
    "                # floating_mems = x_pos[:, :self.overlapping_part, :]\n",
    "            else:\n",
    "                add = floating_memory + x[:, :self.overlapping_part, :]\n",
    "                floating_memory = self.memory_norm(add)\n",
    "                output_hidden_layers += self.overlapping_part\n",
    "                # output_hidden_layers = torch.cat((output_hidden_layers, x[:, :self.overlapping_part, :]), dim=1)\n",
    "                # floating_mems = torch.cat((floating_mems, floating_memory), dim=1)\n",
    "            del(x_pos)\n",
    "            i += 1\n",
    "\n",
    "        out = torch.cat((floating_memory, x[:, self.overlapping_part:, :]), dim=1)\n",
    "\n",
    "        # print(out.shape)\n",
    "        # out = out[:, -1, :]\n",
    "        out = out.sum(dim=1)\n",
    "        out = self.out_norm(out)\n",
    "        out = self.to_logits(out)\n",
    "        out = self.sigm(out)\n",
    "        # out = self.out_norm(out)\n",
    "        # out = torch.tanh(out)\n",
    "        # out = (out >= 0.5).long()\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optim == 'adagrad':\n",
    "            optimizer = torch.optim.Adagrad(\n",
    "                self.parameters(),\n",
    "                lr=self.lr_min,\n",
    "                weight_decay=0.01\n",
    "            )\n",
    "        elif self.optim == 'adam':\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(),\n",
    "                lr=self.lr_min,\n",
    "                weight_decay=0.01,\n",
    "                betas=(0.9, 0.999)\n",
    "            )\n",
    "\n",
    "        lr_scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.lr_max,\n",
    "            total_steps=self.steps,\n",
    "            cycle_momentum=False,\n",
    "        )\n",
    "\n",
    "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
    "        # return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xs, ys, attention = batch\n",
    "        x = torch.tensor(xs).to(\"cpu\")\n",
    "        y = torch.tensor(ys).to(self.device)\n",
    "        attention = torch.tensor(attention).to(\"cpu\")\n",
    "        \n",
    "        x = self.forward(x, attention)        \n",
    "\n",
    "        loss = F.binary_cross_entropy(x, y)\n",
    "        \n",
    "        metrics = compute_metrics(x.detach().cpu().numpy(), y.long().cpu().numpy())\n",
    "        \n",
    "        self.log('train/f1', metrics['f1'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('train/accuracy', metrics['accuracy'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('train/precision', metrics['precision'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('train/recall', metrics['recall'], prog_bar=True, batch_size=x.shape[0])\n",
    "\n",
    "        self.log('train/loss', loss, prog_bar=True, batch_size=x.shape[0])\n",
    "        return {\n",
    "            'loss': loss, \n",
    "            'train_f1': metrics['f1'],\n",
    "            'train_acc': metrics['accuracy'],\n",
    "            'train_precision': metrics['precision'],\n",
    "            'train_recall': metrics['recall']\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        xs, ys, attention = batch\n",
    "        x = torch.tensor(xs).to(\"cpu\")\n",
    "        y = torch.tensor(ys).to(self.device)\n",
    "        attention = torch.tensor(attention).to(\"cpu\")\n",
    "        \n",
    "        x = self.forward(x, attention)        \n",
    "\n",
    "        loss = F.binary_cross_entropy(x, y)\n",
    "        \n",
    "        metrics = compute_metrics(x.cpu().numpy(), y.long().cpu().numpy())\n",
    "        \n",
    "        self.log('eval/f1', metrics['f1'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('eval/accuracy', metrics['accuracy'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('eval/precision', metrics['precision'], prog_bar=True, batch_size=x.shape[0])\n",
    "        self.log('eval/recall', metrics['recall'], prog_bar=True, batch_size=x.shape[0])\n",
    "\n",
    "        self.log('eval/loss', loss, prog_bar=True, batch_size=x.shape[0])\n",
    "        return {\n",
    "            'val_loss': loss, \n",
    "            'val_f1': metrics['f1'],\n",
    "            'val_acc': metrics['accuracy'],\n",
    "            'val_precision': metrics['precision'],\n",
    "            'val_recall': metrics['recall']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e42dfe42-6d42-4ea7-b49a-793803b23e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "petra = PetraRQ(\n",
    "    d_model=d_model,\n",
    "    num_labels=len(unique_labels),\n",
    "    seq_length=seq_length,\n",
    "    overlapping_part=overlapping_part,\n",
    "    steps=steps,\n",
    "    optim=optimizer,\n",
    "    embeddings=embeds,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22814f49-d52c-41c7-bbc4-2cf8ff5acf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 19:33:40,532 - ERROR - wandb.jupyter -  Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: bmarcin. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Praca\\PetraRQ2\\PetraRQ\\notebooks\\PetraRQ\\wandb\\run-20220826_193343-26teari3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/bmarcin/PetraRQ/runs/26teari3\" target=\"_blank\">PetraRQ_classifier_recurrent_roberta</a></strong> to <a href=\"https://wandb.ai/bmarcin/PetraRQ\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    project=\"PetraRQ\",\n",
    "    name=\"PetraRQ_classifier_recurrent_roberta\",\n",
    "    log_model=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c634e7ec-8dbc-46fe-a431-c0373e1cae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_logger.experiment.config['batch_size'] = train_batch_size\n",
    "# wandb_logger.experiment.config['steps'] = steps\n",
    "# wandb_logger.experiment.config['d_model'] = d_model\n",
    "# wandb_logger.experiment.config['num_labels'] = len(unique_labels)\n",
    "# wandb_logger.experiment.config['seq_length'] = seq_length\n",
    "# wandb_logger.experiment.config['depth'] = depth\n",
    "# wandb_logger.experiment.config['heads'] = heads\n",
    "# wandb_logger.experiment.config['dropout'] = dropout\n",
    "# wandb_logger.experiment.config['optimizer'] = optimizer\n",
    "# wandb_logger.experiment.config['duplicate_dataset_ratio'] = duplicate_dataset_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afcfc6b5-dd19-4e15-b903-45e4cded1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    devices=1,\n",
    "    max_steps=steps,\n",
    "    log_every_n_steps=5,\n",
    "    accelerator='gpu',\n",
    "    # accumulate_grad_batches=accumulate_grad_batches,\n",
    "    val_check_interval=0.05,\n",
    "    # val_check_interval=300,\n",
    "    default_root_dir='./PetraRQmodel',\n",
    "    enable_checkpointing=False,\n",
    "    callbacks=[\n",
    "        # ModelCheckpoint(\n",
    "        #     dirpath='./PetraRQmodel/checkpoints',\n",
    "        #     save_top_k=3,\n",
    "        #     monitor='eval/loss',\n",
    "        #     mode='min',\n",
    "        #     filename='petrarq-{epoch}-{val_loss:.2f}.ckpt'\n",
    "        # ),\n",
    "        EarlyStopping(\n",
    "            monitor='eval/f1',\n",
    "            mode='min',\n",
    "            patience=4,\n",
    "            check_finite=True,\n",
    "        ),\n",
    "        LearningRateMonitor(logging_interval='step'),\n",
    "        TQDMProgressBar(refresh_rate=1),\n",
    "        # StochasticWeightAveraging(swa_lrs=1e-3)\n",
    "    ],\n",
    "    logger=wandb_logger,\n",
    "    reload_dataloaders_every_n_epochs=0,\n",
    "    gradient_clip_val=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b15cd5ff-77db-4855-9c22-e723957d6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51273443-3d2c-4c2d-b046-c1d731669e64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61437d16e05e4e1a8456329e37ef63de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainer.validate(petra, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258080e-1203-4680-9784-01891d2bcbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | memory_norm | LayerNorm         | 1.5 K \n",
      "1 | out_norm    | LayerNorm         | 1.5 K \n",
      "2 | sigm        | Sigmoid           | 0     \n",
      "3 | embeds      | RobertaEmbeddings | 12.7 M\n",
      "4 | roberta     | RobertaModel      | 98.3 M\n",
      "5 | to_logits   | Linear            | 14.6 K\n",
      "--------------------------------------------------\n",
      "17.7 K    Trainable params\n",
      "98.3 M    Non-trainable params\n",
      "98.3 M    Total params\n",
      "393.391   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76287343b1942e7a028304e79e37410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(petra, train_data_loader, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42969c-d6cb-4355-b9f7-c9fcb2084c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
