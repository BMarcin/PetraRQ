datasetsplit:
  train: 0.85
  test: 0.1
  dev: 0.05
  parts: 3
  sort_by: date #date or hash

datasetrewrite:
  threads: 64

naive_bayes:
  outputs: probabilities #labels or probabilities
  seed: 42
  threads: 8

#language_modeling_train:
#  cuda_visible_devices: [3,4]
#
#  vocab_size: 16000
#  tokenizer_min_frequency: 2
#  max_seq_length: 512
#  mlm_probability: 0.15
#
#  num_attention_heads: 12
#  num_hidden_layers: 12
#  hidden_size: 768
#  hidden_dropout_prob: 0.1
#
#  epochs: 90
#  per_device_train_batch_size: 18
#  per_device_eval_batch_size: 32
#
#classification_train:
#  cuda_visible_devices: [3,4]
#
#  warmup_steps: 500
#  num_train_epochs: 20
#
#  per_device_train_batch_size: 21
#  per_device_eval_batch_size: 30
