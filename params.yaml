datasetsplit:
  train: 0.7
  test: 0.2
  dev: 0.1
  parts: 3

datasetrewrite:
  threads: 64

language_modeling_train:
  cuda_visible_devices: [3,4]

  vocab_size: 16000
  tokenizer_min_frequency: 2
  max_seq_length: 512
  mlm_probability: 0.15

  num_attention_heads: 12
  num_hidden_layers: 12
  hidden_size: 768
  hidden_dropout_prob: 0.1

  epochs: 90
  per_device_train_batch_size: 18
  per_device_eval_batch_size: 32

classification_train:
  cuda_visible_devices: [3,4]

  warmup_steps: 500
  num_train_epochs: 120

  per_device_train_batch_size: 20
  per_device_eval_batch_size: 30
